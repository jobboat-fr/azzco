# Guide de D√©ploiement - AZZ&CO LABS Website

## üìã Pr√©requis

1. **Node.js** 16+ install√©
2. **Ollama** install√© et configur√©
3. **Git** pour le versioning
4. **Compte GitHub** pour le repository

## üöÄ Installation Locale

### 1. Installer les d√©pendances du backend

```bash
cd backend
npm install
```

### 2. Configurer l'environnement

```bash
cp backend/.env.example backend/.env
```

√âditez `backend/.env` avec vos configurations :
```env
PORT=3000
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=llama2
DB_PATH=./data/visitors.db
```

### 3. Installer et configurer Ollama

```bash
# T√©l√©charger Ollama depuis https://ollama.ai
# Installer et d√©marrer Ollama

# T√©l√©charger un mod√®le
ollama pull llama2

# V√©rifier que Ollama fonctionne
ollama list
```

### 4. D√©marrer le backend

```bash
cd backend
npm start
# ou en mode d√©veloppement
npm run dev
```

Le serveur d√©marre sur `http://localhost:3000`

### 5. Tester le site web

Ouvrez `index.html` dans votre navigateur ou servez-le avec un serveur local :

```bash
# Avec Python
python -m http.server 8000

# Avec Node.js (http-server)
npx http-server
```

## üì¶ D√©ploiement sur GitHub

### 1. Cr√©er un nouveau repository GitHub

1. Allez sur GitHub et cr√©ez un nouveau repository
2. Nommez-le (ex: `azzco-website`)
3. Ne cochez PAS "Initialize with README" (nous avons d√©j√† nos fichiers)

### 2. Initialiser Git localement

```bash
cd azzco-website
git init
git add .
git commit -m "Initial commit: AZZ&CO LABS website with Ollama chatbot"
```

### 3. Connecter au repository GitHub

```bash
# Remplacez YOUR_USERNAME et YOUR_REPO_NAME
git remote add origin https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git
git branch -M main
git push -u origin main
```

### 4. Configuration pour le d√©ploiement

#### Option A: GitHub Pages (Frontend uniquement)

1. Allez dans Settings > Pages
2. S√©lectionnez la branche `main` et le dossier `/ (root)`
3. Le site sera disponible sur `https://YOUR_USERNAME.github.io/YOUR_REPO_NAME`

**Note**: Le backend devra √™tre d√©ploy√© s√©par√©ment (voir Option B)

#### Option B: D√©ploiement complet (Frontend + Backend)

Pour d√©ployer le backend, vous avez plusieurs options :

**Heroku:**
```bash
# Installer Heroku CLI
# Cr√©er un app
heroku create azzco-website-backend

# Configurer les variables d'environnement
heroku config:set OLLAMA_API_URL=your_ollama_url
heroku config:set OLLAMA_MODEL=llama2

# D√©ployer
git subtree push --prefix backend heroku main
```

**Railway / Render / Fly.io:**
- Suivez leurs guides de d√©ploiement Node.js
- Configurez les variables d'environnement
- D√©ployez le dossier `backend/`

**VPS (DigitalOcean, AWS, etc.):**
```bash
# SSH dans votre serveur
# Cloner le repository
git clone https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git
cd YOUR_REPO_NAME/backend

# Installer les d√©pendances
npm install --production

# Configurer PM2 ou systemd pour g√©rer le processus
pm2 start server.js --name azzco-backend

# Configurer Nginx comme reverse proxy
```

### 5. Mettre √† jour l'URL de l'API dans le frontend

Si vous d√©ployez le backend sur un autre serveur, mettez √† jour `chatbot.js` :

```javascript
// Dans chatbot.js, ligne ~3
this.apiUrl = 'https://your-backend-url.com/api';
// ou pour production
this.apiUrl = process.env.API_URL || 'http://localhost:3000/api';
```

## üîß Configuration Ollama en Production

### Option 1: Ollama local sur le serveur

```bash
# Installer Ollama sur le serveur
# Configurer pour accepter les connexions distantes
export OLLAMA_HOST=0.0.0.0:11434
```

### Option 2: Ollama Cloud (si disponible)

Mettez √† jour `OLLAMA_API_URL` dans `.env` avec l'URL du service cloud.

### Option 3: API Ollama externe

Utilisez un service qui fournit une API Ollama (ex: OpenRouter, etc.)

## üìä Base de Donn√©es

La base de donn√©es SQLite est cr√©√©e automatiquement au premier d√©marrage dans `backend/data/visitors.db`.

Pour la production, vous pouvez :
- Utiliser SQLite (simple, pour petits volumes)
- Migrer vers PostgreSQL (recommand√© pour la production)
- Utiliser une base de donn√©es cloud (Supabase, PlanetScale, etc.)

## üîí S√©curit√© en Production

1. **Variables d'environnement**: Ne commitez JAMAIS le fichier `.env`
2. **HTTPS**: Utilisez toujours HTTPS en production
3. **Rate Limiting**: D√©j√† configur√©, ajustez selon vos besoins
4. **CORS**: Configurez `FRONTEND_URL` dans `.env` pour limiter les origines
5. **Secrets**: Utilisez des secrets managers pour les cl√©s API

## üìù Checklist de D√©ploiement

- [ ] Backend install√© et test√© localement
- [ ] Ollama install√© et fonctionnel
- [ ] Variables d'environnement configur√©es
- [ ] Base de donn√©es initialis√©e
- [ ] Frontend test√© avec le backend local
- [ ] Repository GitHub cr√©√©
- [ ] Code pouss√© sur GitHub
- [ ] Backend d√©ploy√© (Heroku/Railway/etc.)
- [ ] Frontend d√©ploy√© (GitHub Pages/Vercel/etc.)
- [ ] URL API mise √† jour dans le frontend
- [ ] HTTPS configur√©
- [ ] Tests de bout en bout effectu√©s

## üêõ D√©pannage

### Le chatbot ne r√©pond pas

1. V√©rifiez que le backend est d√©marr√© : `curl http://localhost:3000/health`
2. V√©rifiez qu'Ollama fonctionne : `curl http://localhost:11434/api/tags`
3. V√©rifiez la console du navigateur pour les erreurs
4. V√©rifiez les logs du backend

### Erreurs CORS

1. V√©rifiez que `FRONTEND_URL` est configur√© dans `.env`
2. V√©rifiez que le frontend utilise la bonne URL API
3. V√©rifiez les headers CORS dans `server.js`

### Base de donn√©es ne se cr√©e pas

1. V√©rifiez les permissions du dossier `backend/data/`
2. V√©rifiez que SQLite3 est install√©
3. V√©rifiez les logs pour les erreurs de cr√©ation

## üìû Support

Pour toute question ou probl√®me :
- Email: azerrached3@gmail.com
- LinkedIn: [Azer Rached](https://www.linkedin.com/in/azer-rached-239258377/)

---

¬© 2025 AZZ&CO LABS. Tous droits r√©serv√©s.